- social media platform	
- OSINT & WEBINT
-threat intelligence reports (including threat landscape and asset-based intelligence).
-----------------------
D3fend- knowledge graph 	 vocabulary used to describe defensive cyber security function and techniques
detect,deny and disrupt

MITRE CRIT - Collaborative Reasearch Into ThreatsS

You are researching the techniques used by APT41 and want the most detailed information.  Which section of the groupâ€™s page on the ATT&CK website should I look to for original source materials?
Meta information
Techniques Used
Source Intelligence
Resources

One of the best ways to truly test and build upon a threat informed defense is to:
Provide red team reports to the SOC
Subscribe to a commercial threat feed
Enable collaboration between red and blue teams through a purple team.
Utilze STIX/TAXII
---------------------------------
CTID - Center Threat Informed Defense
  - CTI
  - defensive engagement of the threat
  - sharing and collaboration
-------------------------------------

AI model training & deployment.
TensorFlow, Scikit learn and PyTorch. 
You will be responsible for designing, developing, and deploying AI applications leveraging both open-source models (Llama, Mistral, DeepSeek etc) 
and proprietary services (OpenAI, Anthropic)
Lead the AI integration efforts within Astra Security, shaping the companyâ€™s AI roadmap
Develop and Optimize Retrieval-Augmented Generation (RAG) Pipelines with multi-tenant capabilities
Build and enhance RAG applications using LangChain, LangGraph, and vector databases (e.g. Milvus, Pinecone, pgvector).
Implement efficient document chunking, retrieval, and ranking strategies.
Optimize LLM interactions using embeddings, prompt engineering, and memory mechanisms.
Work with Graph databases (Neo4j or similar) for structuring and querying knowledge bases
Design multi-agent workflows using orchestration platforms like LangGraph or other emerging agent frameworks for AI-driven decision-making and reasoning.
Integrate vector search, APIs and external knowledge sources into agent workflows.
Exposure to end-to-end AI ecosystem like Huggingface to accelerate AI development (while initial work wonâ€™t involve extensive model training, the candidate should be ready for fine-tuning, domain adaptation, and LLM deployment when needed)
Design and develop AI applications using LLMs (Llama, Mistral, OpenAI, Anthropic, etc.)
Build APIs and microservices to integrate AI models into backend architectures..
Collaborate with the product and engineering teams to integrate AI into Astra Securityâ€™s core offerings
Stay up to date with the latest advancements in AI and security, ensuring Astra remains at the cutting edge
-----------
fine tuning models
LangChain and LangGraph
agentic AI systems in production (e.g., AWS, GCP, Azure) using containerization (Docker, Kubernetes).
Git, Docker, RESTful APIs, FAST APIS observability platform
AI applications using ComfyUI and other GUI-based tools.
 deployment, API integration, and UI development.
Familiarity with AI Agents like Autogen, CrewAI, and AssistantAPIs.
MLOps, model deployment, and monitoring
------------------------------------------
1. Model Fine-Tuning (Phase 8)
ğŸ“Œ Purpose:
To adapt a general-purpose LLM (like Llama/Mistral) to better understand and generate outputs specific to cybersecurity threat intelligence (CTI) tasks.
ğŸ“¥ Inputs:
Cleaned and labeled threat intel data from earlier phases (e.g., labeled TTPs, actor behaviors, threat reports).
Pretrained open-source LLMs (e.g., Mistral, Llama 3, TinyLlama).
ğŸ“¤ Outputs:
A smaller, fine-tuned model that performs better on CTI-specific NLP tasks like summarization, correlation, IOC detection, etc.
Optionally quantized for fast inference (GGUF/Ollama format).
ğŸ’¡ Value to Project:
Improves accuracy and relevance of threat extractions and reasoning by tailoring the model to our domain.
Reduces dependency on costly APIs like OpenAI/Anthropic.
Enables local/private use in sensitive org environments.
ğŸ”„ How it ties back:
Earlier steps (data ingestion, preprocessing) feed into this, and the fine-tuned model becomes a core component used in RAG, agents, and chat interface.
âœ… 2. Backend Deployment (Phase 9)
ğŸ“Œ Purpose:
To expose AI models, agent workflows, and RAG search results through secure, scalable APIs so they can be used in the UI, dashboards, or by external systems.
ğŸ“¥ Inputs:
Trained or fine-tuned models
FastAPI microservices
Containerized apps using Docker
Business logic from multi-agent systems
ğŸ“¤ Outputs:
REST APIs (e.g., /analyze, /extract_ttp, /search_actor, etc.)
Deployed infrastructure on cloud or local servers (via Docker, Kubernetes)
ğŸ’¡ Value to Project:
Makes the system accessible, modular, and production-ready
Enables integration with external CTI platforms, internal SIEMs, or SOC dashboards
Ensures fault-tolerant, scalable, and secure access to intelligence generation
ğŸ”„ How it ties back:
All the AI/ML logic is "served" here â€” without this, our models and agents are not usable by analysts or apps.
âœ… 3. MLOps & Monitoring (Phase 10)
ğŸ“Œ Purpose:
To manage, automate, and monitor the entire ML lifecycle â€” from model training to deployment to performance tracking.
ğŸ“¥ Inputs:
Model training jobs and outputs
Inference logs and user interaction data
Infrastructure usage metrics
ğŸ“¤ Outputs:
CI/CD pipelines (auto-deploy new models, API updates)
Dashboards (Grafana, Prometheus) for real-time monitoring
Performance reports, usage stats, drift detection alerts
ğŸ’¡ Value to Project:
Ensures reliability, traceability, and continuous improvement
Allows us to detect issues like: model degradation, long response times, or broken APIs
Supports iterative updates and model re-training
ğŸ”„ How it ties back:
Without this, long-term maintenance of the system is painful. With MLOps, we ensure the system stays healthy, current, and continuously improves.
ğŸ” How These Phases Strengthen the Whole System
Phase	Improves	How
Model Fine-Tuning	Accuracy	Tailors LLMs to CTI tasks, improves threat recognition
Backend Deployment	Usability	Exposes models and agents to users and external systems
MLOps & Monitoring	Maintainability & Scaling	Automates lifecycle, tracks usage, and enables CI/CD
